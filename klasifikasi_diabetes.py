# -*- coding: utf-8 -*-
"""Klasifikasi Diabetes.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Pcl02GUT_octhNDQmVob9tlqKGW5xSwi

# Klasifikasi Penyakit Diabetes

## Import Library
"""

# 1. Import Library
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

from sklearn.model_selection import GridSearchCV
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix
import joblib

"""## Data Understanding"""

# 2. Data Understanding - Mount Google Drive dan Load Dataset

from google.colab import drive
drive.mount('/content/drive')

df = pd.read_csv('/content/drive/MyDrive/submission/FORCASTING/diabetes_prediction_dataset.csv')
df.head()

df.info()

df.shape

df.describe()

"""Distribusi target"""

df['diabetes'].value_counts(normalize=True)

colors = plt.cm.Greens(np.linspace(0.5, 0.8, 2))  # dua warna dari colormap Greens
df['diabetes'].value_counts(normalize=True).plot(kind='bar', color=colors)
plt.title('Distribusi Target: Diabetes')
plt.xticks([0, 1], ['Negatif (0)', 'Positif (1)'], rotation=0)
plt.ylabel('Proporsi')
plt.show()

print("Gender:", df['gender'].unique())
print("Smoking History:", df['smoking_history'].unique())

df.corr(numeric_only=True)

plt.figure(figsize=(10,6))
sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='Greens')
plt.title('Korelasi Antar Fitur Numerik')
plt.show()

num_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']
colors = plt.cm.Greens(np.linspace(0.4, 0.8, len(num_cols)))  # pilih warna dari colormap Greens

fig, axes = plt.subplots(2, 2, figsize=(10, 8))
axes = axes.flatten()

for i, col in enumerate(num_cols):
    df[col].hist(bins=30, ax=axes[i], color=colors[i])
    axes[i].set_title(col)

plt.tight_layout()
plt.show()

"""### Summary :

- Total data: 100.000 baris, 9 kolom
- Target: diabetes (0/1), imbalanced → positif cuma 8.5%
- Fitur penting (korelasi tinggi ke diabetes):
  - HbA1c_level → 0.40 ✅
  - blood_glucose_level → 0.42 ✅
- Distribusi usia: Banyak lansia (usia 80 meledak)
- BMI & gula darah: Ada outlier ekstrem
- Fitur kategorikal: gender, smoking_history → perlu di-encode
- Data bersih: Ga ada missing value


note : mesikipun ada kemungkinan outliers untuk saat ini belom di berishkan terlebih dahulu untuk melihat perbandingannya saat evaluasi. jika mempengaruhi maka akan di drop semua outliers jika tidak maka akan di biarkan

## Data Preparations

Karena tidak ada missing value maka akan saya lakukan Label Encoder untuk gender dan One-hot encode untuk 'smoking_history' dan Normalisasi untuk age, bmi, HbA1c_level, blood_glucose_level. terakhir akan di pisahkan antara fitur dan target lalu di split untuk train dan test
"""

df_clean = df.copy()
df_clean.head()

# Encoding gender
le = LabelEncoder()
df_clean['gender'] = le.fit_transform(df_clean['gender'])

df_clean

# One-hot encoding untuk smoking_history
df_clean = pd.get_dummies(df_clean, columns=['smoking_history'])

# Normalisasi
scaler = MinMaxScaler()
num_cols = ['age', 'bmi', 'HbA1c_level', 'blood_glucose_level']
df_clean[num_cols] = scaler.fit_transform(df_clean[num_cols])

df_clean.head(3)

"""Pisah fitur dan target"""

X = df_clean.drop('diabetes', axis=1)
y = df_clean['diabetes']

"""Pembagian dataset train dan test dengan rasio 80/20"""

X_train, X_test, y_train, y_test = train_test_split(
  X, y, test_size=0.2, random_state=27, stratify=y
)

"""## Modeling

- Logistic Regression
- Random Forest
- Gradient Bosting

### Logistic Regression
"""

logreg = LogisticRegression(max_iter=1000, random_state=27)
logreg.fit(X_train, y_train)

y_pred_logreg = logreg.predict(X_test)

from sklearn.metrics import classification_report, confusion_matrix

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_logreg))
print("\nClassification Report:\n", classification_report(y_test, y_pred_logreg))

"""### Random Forest"""

rf = RandomForestClassifier(n_estimators=100, random_state=27)
rf.fit(X_train, y_train)

y_pred_rf = rf.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_rf))
print("\nClassification Report:\n", classification_report(y_test, y_pred_rf))

"""### XGBost"""

xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=27)
xgb.fit(X_train, y_train)

y_pred_xgb = xgb.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb))
print("\nClassification Report:\n", classification_report(y_test, y_pred_xgb))

report_logreg = classification_report(y_test, y_pred_logreg, output_dict=True)
report_rf = classification_report(y_test, y_pred_rf, output_dict=True)
report_xgb = classification_report(y_test, y_pred_xgb, output_dict=True)

df_eval = pd.DataFrame({
    'accuracy' : {
        'Logistic Regression': round(report_logreg['accuracy']*100),
        'Random Forest': round(report_rf['accuracy']*100),
        'XGBoost': round(report_xgb['accuracy']*100)
    },
    'precision' : {
        'Logistic Regression': round(report_logreg['1']['precision']*100),
        'Random Forest': round(report_rf['1']['precision']*100),
        'XGBoost': round(report_xgb['1']['precision']*100)
    },
    'recall' : {
        'Logistic Regression': round(report_logreg['1']['recall']*100),
        'Random Forest': round(report_rf['1']['recall']*100),
        'XGBoost': round(report_xgb['1']['recall']*100)
    },
    'F1-Score' : {
        'Logistic Regression': round(report_logreg['1']['f1-score']*100),
        'Random Forest': round(report_rf['1']['f1-score']*100),
        'XGBoost': round(report_xgb['1']['f1-score']*100)
    }
})

df_eval

# Ubah ke format long agar bisa digambar oleh seaborn
df_plot = df_eval.reset_index().melt(id_vars='index', var_name='Metrik', value_name='Skor')
df_plot.rename(columns={'index': 'Model'}, inplace=True)

# Ambil 3 warna dari cmap 'Greens'
green_palette = sns.color_palette("Greens", n_colors=4)[1:]  # Ambil warna 1-3 agar tetap kontras

# Buat plot
plt.figure(figsize=(10, 6))
sns.barplot(data=df_plot, x='Metrik', y='Skor', hue='Model', palette=green_palette)

# Visualisasi tambahan
plt.title('Perbandingan Performa Model Machine Learning')
plt.ylim(0, 100)
plt.ylabel('Skor (%)')
plt.xlabel('Metrik Evaluasi')
plt.legend(title='Model', loc='lower right')
plt.grid(axis='y', linestyle='--', alpha=0.5)
plt.tight_layout()

plt.show()

"""### Summary :

| Model               | Accuracy | Precision | Recall | F1-Score |
| ------------------- | -------: | --------: | -----: | -------: |
| Logistic Regression |      96% |       88% |    63% |      74% |
| Random Forest       |      97% |       93% |    69% |      79% |
| XGBoost             |      97% |       96% |    69% |      80% |

#### ✅ Catatan:

* **XGBoost** memiliki performa terbaik berdasarkan **Precision** dan **F1-Score** tertinggi.
* **Recall relatif rendah (sekitar 69%)** — ini berarti model masih bisa melewatkan sejumlah kasus positif, sehingga perlu perhatian lebih untuk **hyperparameter tuning** atau metode lain agar recall meningkat.
* Secara keseluruhan, trade-off antara precision dan recall harus diperhatikan sesuai prioritas aplikasi (misalnya, untuk deteksi penyakit, recall sering lebih penting).

## Evaluation

### **Metrik Evaluasi untuk Klasifikasi Biner**

| Metrik        | Rumus                                                                                                 | Keterangan Singkat                                                        |
| ------------- | ----------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------- |
| **Accuracy**  | $\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}$                                                 | Seberapa banyak prediksi model yang benar secara keseluruhan              |
| **Precision** | $\text{Precision} = \frac{TP}{TP + FP}$                                                               | Dari semua prediksi positif, berapa yang benar-benar positif              |
| **Recall**    | $\text{Recall} = \frac{TP}{TP + FN}$                                                                  | Dari semua kasus sebenarnya positif, berapa yang berhasil dikenali model  |
| **F1-Score**  | $\text{F1} = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}$ | Rata-rata harmonik dari precision dan recall, berguna saat data imbalance |

---

#### Keterangan:

* **TP** (True Positive): Model memprediksi positif dan memang positif
* **TN** (True Negative): Model memprediksi negatif dan memang negatif
* **FP** (False Positive): Model memprediksi positif tapi salah
* **FN** (False Negative): Model memprediksi negatif tapi ternyata positif

Mengacu pada Summary Modeling dimana model paling baik jatuh pada XGBoost, dimana akan dilakukan tunning dengan harapan dapat memperbaiki menjadi lebih baik lagi
"""

param_grid = {
  'n_estimators': [100, 200],
  'max_depth': [3, 5, 7],
  'learning_rate': [0.01, 0.1, 0.2],
  'subsample': [0.8, 1.0]
}

xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)

grid_search = GridSearchCV(
    estimator=xgb,
    param_grid=param_grid,
    cv=3,
    n_jobs=-1,
    scoring='f1',  # fokus ke f1-score untuk label positif
    verbose=1
)

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)

best_xgb = grid_search.best_estimator_
y_pred_xgb_tuned = best_xgb.predict(X_test)

print("Confusion Matrix:\n", confusion_matrix(y_test, y_pred_xgb_tuned))
print("\nClassification Report:\n", classification_report(y_test, y_pred_xgb_tuned))

report_xgb_best = classification_report(y_test, y_pred_xgb_tuned, output_dict=True)

# Ambil nilai dari report_xgb_best
tuned_metrics = {
    'accuracy': round(report_xgb_best['accuracy'] * 100),
    'precision': round(report_xgb_best['1']['precision'] * 100),
    'recall': round(report_xgb_best['1']['recall'] * 100),
    'F1-Score': round(report_xgb_best['1']['f1-score'] * 100),
}

df_tuned = pd.DataFrame(tuned_metrics, index=['XGBoost Tuned'])

df_eval = pd.concat([df_eval, df_tuned])

df_eval

"""### Summary :

#### **Model-Model yang Dicoba**

| Model               | Accuracy | Precision | Recall | F1-Score |
| ------------------- | -------: | --------: | -----: | -------: |
| Logistic Regression |      96% |       88% |    63% |      74% |
| Random Forest       |      97% |       93% |    69% |      79% |
| XGBoost             |      97% |       96% |    69% |      80% |
| XGBoost Tuned       |      97% |       97% |    69% |      81% |

> Semua model memiliki akurasi tinggi (>96%), tetapi model terbaik dari segi keseimbangan metrik adalah **XGBoost yang sudah dituning**.

---

#### **Evaluasi Visual**

* Telah dilakukan **visualisasi prediksi vs aktual** untuk XGBoost → menunjukkan distribusi prediksi yang baik.
* Tidak terlihat tanda-tanda **overfitting**: model generalisasi dengan baik pada data uji.

---

#### **Kesimpulan**

* Model **XGBoost (tuned)** memberikan performa terbaik secara keseluruhan: **akurasi tinggi**, **precision bagus**, dan **recall lebih baik** dibanding model lain.
* Cocok dipilih sebagai **model final** untuk prediksi diabetes dalam dataset ini.
* Evaluasi dilakukan secara menyeluruh menggunakan **Confusion Matrix, Classification Report**, dan **Visualisasi Hasil**.
"""

# Simpan model ke file .pkl
joblib.dump(best_xgb, 'xgboost_diabetes_model.pkl')
print("Model XGBoost berhasil disimpan sebagai 'xgboost_diabetes_model.pkl'")

df_clean_lagi = df.copy()
df_clean_lagi.head()

df_clean

# Inisialisasi encoder
gender_encoder = LabelEncoder()
smoke_encoder = LabelEncoder()

# Fit ke data asli
df_clean_lagi['gender'] = gender_encoder.fit_transform(df_clean_lagi['gender'])
df_clean_lagi['smoking_history'] = smoke_encoder.fit_transform(df_clean_lagi['smoking_history'])

# Simpan encoder
encoders = {
    "gender": gender_encoder,
    "smoking_history": smoke_encoder
}
joblib.dump(encoders, "label_encoders.pkl")

df_clean_lagi